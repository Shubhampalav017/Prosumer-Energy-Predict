{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":57236,"databundleVersionId":7292407,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-18T15:36:05.735289Z","iopub.execute_input":"2024-07-18T15:36:05.735725Z","iopub.status.idle":"2024-07-18T15:36:05.795779Z","shell.execute_reply.started":"2024-07-18T15:36:05.735696Z","shell.execute_reply":"2024-07-18T15:36:05.794636Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/predict-energy-behavior-of-prosumers/client.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/gas_prices.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/electricity_prices.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/weather_station_to_county_mapping.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/public_timeseries_testing_util.py\n/kaggle/input/predict-energy-behavior-of-prosumers/historical_weather.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/county_id_to_name_map.json\n/kaggle/input/predict-energy-behavior-of-prosumers/train.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/forecast_weather.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/sample_submission.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/client.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/gas_prices.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/electricity_prices.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/historical_weather.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/revealed_targets.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/test.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/example_test_files/forecast_weather.csv\n/kaggle/input/predict-energy-behavior-of-prosumers/enefit/competition.cpython-310-x86_64-linux-gnu.so\n/kaggle/input/predict-energy-behavior-of-prosumers/enefit/__init__.py\n","output_type":"stream"}]},{"cell_type":"code","source":"def generate_featuers(\n    df_data,\n    df_client,\n    df_gas_prices,\n    df_electricity_prices,\n    df_forecast_weather,\n    df_historical_weather,\n    df_weather_station_to_county_mapping,\n    train_start_timestep = '2021-09-01 11:00:00',\n    gas_end_date = '2022-01-10 23:00:00'\n    \n    ):\n\n    df_weather_station_to_county_mapping = df_weather_station_to_county_mapping[df_weather_station_to_county_mapping.notnull().all(axis=1)].sort_values(by=\"county\")\n    result_dict = dict(zip(zip(round(df_weather_station_to_county_mapping['latitude'],1), round(df_weather_station_to_county_mapping['longitude'],1)), df_weather_station_to_county_mapping['county']))\n\n    df_historical_weather = df_historical_weather[df_historical_weather['datetime'] >= train_start_timestep]\n\n    \n    #Merge df_data and df_client\n    df_client_try = df_client.copy(deep=True)\n    df_client_try['date'] = pd.to_datetime(df_client_try['date'])\n    df_client_try['datetime'] = df_client_try['date'].apply(lambda x: [x + pd.Timedelta(hours=i) for i in range(24)])\n    df_client_try = df_client_try.explode('datetime')\n    df_client_try = df_client_try.drop(['date','data_block_id'], axis=1)\n    \n    df_data['datetime'] = pd.to_datetime(df_data['datetime'])\n    df_data = df_data.merge(df_client_try, on=['county','product_type','is_business','datetime'], how='left')\n\n    endDate = df_client_try['datetime'].max()\n    df_data = df_data[df_data['datetime'] <= endDate]\n    \n\n    #Merge df_data and df_gas_prices\n    df_gas_try = df_gas_prices.copy(deep=True)\n    df_gas_try['forecast_date'] = pd.to_datetime(df_gas_try['forecast_date'])\n    df_gas_try['datetime'] = df_gas_try['forecast_date'].apply(lambda x: [x + pd.Timedelta(hours=i) for i in range(24)])\n    df_gas_try = df_gas_try.explode('datetime')\n    df_gas_try = df_gas_try.drop(['forecast_date' , 'origin_date' , 'data_block_id'], axis=1)\n    gas_end_date = df_gas_try['datetime'].max()\n    df_data = df_data[df_data['datetime'] <= gas_end_date]\n    df_data = df_data.merge(df_gas_try, on=['datetime'], how='left')\n\n    #Merge df_data and df_electricity_prices\n    df_electricity_prices_try = df_electricity_prices.copy(deep=True)\n    df_electricity_prices_try.drop(columns=[\"origin_date\" , 'data_block_id'], inplace=True)\n    df_electricity_prices_try['forecast_date'] = pd.to_datetime(df_electricity_prices_try['forecast_date'])\n    df_electricity_prices_try.rename(columns={\"forecast_date\": \"datetime\"}, inplace=True)\n    df_data = df_data.merge(df_electricity_prices_try, on=['datetime'], how='left')\n\n    #Merge df_data and df_forecast_weather\n    df_forecast_weather_copy = df_forecast_weather.copy(deep=True)\n    df_forecast_weather_copy['county'] = [result_dict.get((x, y), -1) for x, y in zip(df_forecast_weather_copy['latitude'], df_forecast_weather_copy['longitude'])]\n    df_forecast_weather_copy = df_forecast_weather_copy[df_forecast_weather_copy['county']!=-1]\n    df_forecast_weather_copy['origin_datetime'] = pd.to_datetime(df_forecast_weather_copy['origin_datetime'])\n    df_forecast_weather_copy['origin_datetime'] = pd.to_datetime(df_forecast_weather_copy['origin_datetime'].dt.date.astype(str) + ' 02:00:00')\n    df_forecast_weather_copy['forecast_datetime'] = df_forecast_weather_copy['origin_datetime'] + pd.to_timedelta(df_forecast_weather_copy['hours_ahead'], unit='h')\n    df_forecast_weather_copy = df_forecast_weather_copy.drop('origin_datetime',axis=1)\n    df_forecast_weather_copy = df_forecast_weather_copy.sort_values(by=['latitude','longitude','forecast_datetime', 'hours_ahead'])\n    df_forecast_weather_copy['cumcount'] = (df_forecast_weather_copy['hours_ahead']-1)//24+1\n    \n    columns_to_average = [col for col in df_forecast_weather_copy.columns if col not in ['latitude', 'longitude', 'hours_ahead' , 'forecast_datetime','cumcount']]\n    agg_dict = {col: 'mean' for col in columns_to_average}\n    agg_dict['cumcount'] = 'first'  # to preserve the cumcount value\n    df_forecast_weather_copy = df_forecast_weather_copy.groupby(['county','forecast_datetime', 'cumcount']).agg(agg_dict)\n    df_forecast_weather_copy=df_forecast_weather_copy.unstack(level=-1)\n    df_forecast_weather_copy.columns = [f'{col[0]}_{col[1]}' for col in df_forecast_weather_copy.columns]\n    df_forecast_weather_copy.reset_index(inplace=True)\n    df_forecast_weather_copy.rename(columns={'forecast_datetime': 'datetime'}, inplace=True)\n    df_forecast_weather_copy = df_forecast_weather_copy.drop(['county_1','county_2','cumcount_1','cumcount_2'],axis=1)\n    df_forecast_weather_copy.fillna(0, inplace=True)\n    \n    df_data = df_data.merge(df_forecast_weather_copy, on=['county','datetime'], how='left')\n\n\n    #Merge df_data and df_historical_weather\n    df_historical_weather_copy = df_historical_weather.copy(deep=True)\n    df_historical_weather_copy['datetime'] = pd.to_datetime(df_historical_weather_copy['datetime'])\n    df_historical_weather_copy['county'] = [result_dict.get((x, y), -1) for x, y in zip(df_historical_weather_copy['latitude'], df_historical_weather_copy['longitude'])]\n    df_historical_weather_copy = df_historical_weather_copy[df_historical_weather_copy['county']!=-1]\n    df_historical_weather_copy = df_historical_weather_copy.sort_values(by=['latitude','longitude','datetime'])\n    columns_to_average = [col for col in df_historical_weather_copy.columns if col not in ['latitude', 'longitude', 'datetime','county','data_block_id']]\n    agg_dict = {col: 'mean' for col in columns_to_average}\n    df_historical_weather_copy = df_historical_weather_copy.groupby(['county','datetime']).agg(agg_dict)\n    df_historical_weather_copy.reset_index(inplace=True)\n\n    df_data = df_data.merge(df_historical_weather_copy, on=['county','datetime'], how='left')\n\n    return df_data","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:36:05.798202Z","iopub.execute_input":"2024-07-18T15:36:05.798750Z","iopub.status.idle":"2024-07-18T15:36:05.821696Z","shell.execute_reply.started":"2024-07-18T15:36:05.798710Z","shell.execute_reply":"2024-07-18T15:36:05.820453Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/predict-energy-behavior-of-prosumers/\"\n# Read CSVs and parse relevant date columns\ndf_data = pd.read_csv(DATA_DIR + \"train.csv\")\ndf_client = pd.read_csv(DATA_DIR + \"client.csv\")\ndf_historical_weather = pd.read_csv(DATA_DIR + \"historical_weather.csv\")\ndf_forecast_weather = pd.read_csv(DATA_DIR + \"forecast_weather.csv\")\ndf_electricity_prices = pd.read_csv(DATA_DIR + \"electricity_prices.csv\")\ndf_gas_prices = pd.read_csv(DATA_DIR + \"gas_prices.csv\")\ndf_weather_station_to_county_mapping = pd.read_csv(DATA_DIR + \"weather_station_to_county_mapping.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:36:05.823254Z","iopub.execute_input":"2024-07-18T15:36:05.823695Z","iopub.status.idle":"2024-07-18T15:36:46.089026Z","shell.execute_reply.started":"2024-07-18T15:36:05.823658Z","shell.execute_reply":"2024-07-18T15:36:46.087361Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"combined_df = generate_featuers(\n    df_data,\n    df_client,\n    df_gas_prices,\n    df_electricity_prices,\n    df_forecast_weather,\n    df_historical_weather,\n    df_weather_station_to_county_mapping)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:36:46.092537Z","iopub.execute_input":"2024-07-18T15:36:46.093031Z","iopub.status.idle":"2024-07-18T15:37:06.075458Z","shell.execute_reply.started":"2024-07-18T15:36:46.092988Z","shell.execute_reply":"2024-07-18T15:37:06.074344Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"combined_df.to_csv('/kaggle/working/combined_df.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:37:06.077272Z","iopub.execute_input":"2024-07-18T15:37:06.077712Z","iopub.status.idle":"2024-07-18T15:39:00.594769Z","shell.execute_reply.started":"2024-07-18T15:37:06.077681Z","shell.execute_reply":"2024-07-18T15:39:00.593777Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"combined_df.columns","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:39:00.596625Z","iopub.execute_input":"2024-07-18T15:39:00.597031Z","iopub.status.idle":"2024-07-18T15:39:00.605395Z","shell.execute_reply.started":"2024-07-18T15:39:00.596991Z","shell.execute_reply":"2024-07-18T15:39:00.604364Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Index(['county', 'is_business', 'product_type', 'target', 'is_consumption',\n       'datetime', 'data_block_id', 'row_id', 'prediction_unit_id',\n       'eic_count', 'installed_capacity', 'lowest_price_per_mwh',\n       'highest_price_per_mwh', 'euros_per_mwh', 'temperature_1',\n       'temperature_2', 'dewpoint_1', 'dewpoint_2', 'cloudcover_high_1',\n       'cloudcover_high_2', 'cloudcover_low_1', 'cloudcover_low_2',\n       'cloudcover_mid_1', 'cloudcover_mid_2', 'cloudcover_total_1',\n       'cloudcover_total_2', '10_metre_u_wind_component_1',\n       '10_metre_u_wind_component_2', '10_metre_v_wind_component_1',\n       '10_metre_v_wind_component_2', 'data_block_id_1', 'data_block_id_2',\n       'direct_solar_radiation_1', 'direct_solar_radiation_2',\n       'surface_solar_radiation_downwards_1',\n       'surface_solar_radiation_downwards_2', 'snowfall_1', 'snowfall_2',\n       'total_precipitation_1', 'total_precipitation_2', 'temperature',\n       'dewpoint', 'rain', 'snowfall', 'surface_pressure', 'cloudcover_total',\n       'cloudcover_low', 'cloudcover_mid', 'cloudcover_high', 'windspeed_10m',\n       'winddirection_10m', 'shortwave_radiation', 'direct_solar_radiation',\n       'diffuse_radiation'],\n      dtype='object')"},"metadata":{}}]},{"cell_type":"code","source":"grp = combined_df.groupby(['county','is_business','product_type','is_consumption'])","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:39:00.606981Z","iopub.execute_input":"2024-07-18T15:39:00.607430Z","iopub.status.idle":"2024-07-18T15:39:00.618112Z","shell.execute_reply.started":"2024-07-18T15:39:00.607372Z","shell.execute_reply":"2024-07-18T15:39:00.616941Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"grp.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:39:00.619684Z","iopub.execute_input":"2024-07-18T15:39:00.620084Z","iopub.status.idle":"2024-07-18T15:39:00.881181Z","shell.execute_reply.started":"2024-07-18T15:39:00.620049Z","shell.execute_reply":"2024-07-18T15:39:00.880076Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"         county  is_business  product_type  target  is_consumption  \\\n0             0            0             1   0.713               0   \n1             0            0             1  96.590               1   \n2             0            0             2   0.000               0   \n3             0            0             2  17.314               1   \n4             0            0             3   2.904               0   \n...         ...          ...           ...     ...             ...   \n1338977      14            1             2  22.009               1   \n1339114      14            1             2   0.000               0   \n1339115      14            1             2  25.434               1   \n1339252      14            1             2   0.000               0   \n1339253      14            1             2  24.024               1   \n\n                   datetime  data_block_id   row_id  prediction_unit_id  \\\n0       2021-09-01 00:00:00              0        0                   0   \n1       2021-09-01 00:00:00              0        1                   0   \n2       2021-09-01 00:00:00              0        2                   1   \n3       2021-09-01 00:00:00              0        3                   1   \n4       2021-09-01 00:00:00              0        4                   2   \n...                     ...            ...      ...                 ...   \n1338977 2022-11-01 02:00:00            426  1338977                  68   \n1339114 2022-11-01 03:00:00            426  1339114                  68   \n1339115 2022-11-01 03:00:00            426  1339115                  68   \n1339252 2022-11-01 04:00:00            426  1339252                  68   \n1339253 2022-11-01 04:00:00            426  1339253                  68   \n\n         eic_count  ...  surface_pressure  cloudcover_total  cloudcover_low  \\\n0            108.0  ...               NaN               NaN             NaN   \n1            108.0  ...               NaN               NaN             NaN   \n2             17.0  ...               NaN               NaN             NaN   \n3             17.0  ...               NaN               NaN             NaN   \n4            688.0  ...               NaN               NaN             NaN   \n...            ...  ...               ...               ...             ...   \n1338977        5.0  ...       1009.833333         99.666667           100.0   \n1339114        5.0  ...       1009.566667         99.000000           100.0   \n1339115        5.0  ...       1009.566667         99.000000           100.0   \n1339252        5.0  ...       1009.333333         92.000000           100.0   \n1339253        5.0  ...       1009.333333         92.000000           100.0   \n\n         cloudcover_mid  cloudcover_high  windspeed_10m  winddirection_10m  \\\n0                   NaN              NaN            NaN                NaN   \n1                   NaN              NaN            NaN                NaN   \n2                   NaN              NaN            NaN                NaN   \n3                   NaN              NaN            NaN                NaN   \n4                   NaN              NaN            NaN                NaN   \n...                 ...              ...            ...                ...   \n1338977        6.000000        26.333333       4.111111         224.333333   \n1339114        2.000000        35.333333       3.805556         218.333333   \n1339115        2.000000        35.333333       3.805556         218.333333   \n1339252        0.333333         6.333333       3.472222         213.000000   \n1339253        0.333333         6.333333       3.472222         213.000000   \n\n         shortwave_radiation  direct_solar_radiation  diffuse_radiation  \n0                        NaN                     NaN                NaN  \n1                        NaN                     NaN                NaN  \n2                        NaN                     NaN                NaN  \n3                        NaN                     NaN                NaN  \n4                        NaN                     NaN                NaN  \n...                      ...                     ...                ...  \n1338977                  0.0                     0.0                0.0  \n1339114                  0.0                     0.0                0.0  \n1339115                  0.0                     0.0                0.0  \n1339252                  0.0                     0.0                0.0  \n1339253                  0.0                     0.0                0.0  \n\n[690 rows x 54 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>county</th>\n      <th>is_business</th>\n      <th>product_type</th>\n      <th>target</th>\n      <th>is_consumption</th>\n      <th>datetime</th>\n      <th>data_block_id</th>\n      <th>row_id</th>\n      <th>prediction_unit_id</th>\n      <th>eic_count</th>\n      <th>...</th>\n      <th>surface_pressure</th>\n      <th>cloudcover_total</th>\n      <th>cloudcover_low</th>\n      <th>cloudcover_mid</th>\n      <th>cloudcover_high</th>\n      <th>windspeed_10m</th>\n      <th>winddirection_10m</th>\n      <th>shortwave_radiation</th>\n      <th>direct_solar_radiation</th>\n      <th>diffuse_radiation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.713</td>\n      <td>0</td>\n      <td>2021-09-01 00:00:00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>108.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>96.590</td>\n      <td>1</td>\n      <td>2021-09-01 00:00:00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>108.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>2021-09-01 00:00:00</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>17.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>17.314</td>\n      <td>1</td>\n      <td>2021-09-01 00:00:00</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>17.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2.904</td>\n      <td>0</td>\n      <td>2021-09-01 00:00:00</td>\n      <td>0</td>\n      <td>4</td>\n      <td>2</td>\n      <td>688.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1338977</th>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n      <td>22.009</td>\n      <td>1</td>\n      <td>2022-11-01 02:00:00</td>\n      <td>426</td>\n      <td>1338977</td>\n      <td>68</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>1009.833333</td>\n      <td>99.666667</td>\n      <td>100.0</td>\n      <td>6.000000</td>\n      <td>26.333333</td>\n      <td>4.111111</td>\n      <td>224.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1339114</th>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>2022-11-01 03:00:00</td>\n      <td>426</td>\n      <td>1339114</td>\n      <td>68</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>1009.566667</td>\n      <td>99.000000</td>\n      <td>100.0</td>\n      <td>2.000000</td>\n      <td>35.333333</td>\n      <td>3.805556</td>\n      <td>218.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1339115</th>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n      <td>25.434</td>\n      <td>1</td>\n      <td>2022-11-01 03:00:00</td>\n      <td>426</td>\n      <td>1339115</td>\n      <td>68</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>1009.566667</td>\n      <td>99.000000</td>\n      <td>100.0</td>\n      <td>2.000000</td>\n      <td>35.333333</td>\n      <td>3.805556</td>\n      <td>218.333333</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1339252</th>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>0</td>\n      <td>2022-11-01 04:00:00</td>\n      <td>426</td>\n      <td>1339252</td>\n      <td>68</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>1009.333333</td>\n      <td>92.000000</td>\n      <td>100.0</td>\n      <td>0.333333</td>\n      <td>6.333333</td>\n      <td>3.472222</td>\n      <td>213.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1339253</th>\n      <td>14</td>\n      <td>1</td>\n      <td>2</td>\n      <td>24.024</td>\n      <td>1</td>\n      <td>2022-11-01 04:00:00</td>\n      <td>426</td>\n      <td>1339253</td>\n      <td>68</td>\n      <td>5.0</td>\n      <td>...</td>\n      <td>1009.333333</td>\n      <td>92.000000</td>\n      <td>100.0</td>\n      <td>0.333333</td>\n      <td>6.333333</td>\n      <td>3.472222</td>\n      <td>213.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>690 rows × 54 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"grp.describe()","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:39:00.882705Z","iopub.execute_input":"2024-07-18T15:39:00.883004Z","iopub.status.idle":"2024-07-18T15:39:18.073675Z","shell.execute_reply.started":"2024-07-18T15:39:00.882980Z","shell.execute_reply":"2024-07-18T15:39:18.072587Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                 target                      \\\n                                                  count        mean     min   \ncounty is_business product_type is_consumption                                \n0      0           1            0               15260.0  220.606349   0.000   \n                                1               15260.0  442.797622  22.972   \n                   2            0               15260.0    8.372791   0.000   \n                                1               15260.0   23.173754   0.644   \n                   3            0               15260.0  759.214344   0.000   \n...                                                 ...         ...     ...   \n15     1           0            1               13077.0  331.619296  23.526   \n                   1            0               15260.0   41.582167   0.000   \n                                1               15260.0   79.601392   0.485   \n                   3            0               15260.0   94.133136   0.000   \n                                1               15260.0  408.428530  13.591   \n\n                                                                     \\\n                                                      25%       50%   \ncounty is_business product_type is_consumption                        \n0      0           1            0                 0.18300    1.5010   \n                                1               185.90725  379.2575   \n                   2            0                 0.00000    0.0010   \n                                1                10.93075   21.3120   \n                   3            0                 1.64175    8.6195   \n...                                                   ...       ...   \n15     1           0            1               178.26700  244.6720   \n                   1            0                 0.00000    0.0230   \n                                1                32.20950   55.8570   \n                   3            0                 0.00000    0.7130   \n                                1               281.34600  350.3970   \n\n                                                                      \\\n                                                      75%        max   \ncounty is_business product_type is_consumption                         \n0      0           1            0               112.36225   3445.013   \n                                1               602.03550   1638.667   \n                   2            0                 5.07525    113.911   \n                                1                33.35375     76.821   \n                   3            0               466.78150  11209.014   \n...                                                   ...        ...   \n15     1           0            1               474.40200   1030.669   \n                   1            0                26.43675    474.244   \n                                1                99.91600    426.108   \n                   3            0                53.52350   1421.238   \n                                1               487.99400   1349.640   \n\n                                                            datetime  \\\n                                                        std    count   \ncounty is_business product_type is_consumption                         \n0      0           1            0                509.590282    15264   \n                                1                316.116769    15264   \n                   2            0                 18.232197    15264   \n                                1                 14.296245    15264   \n                   3            0               1664.822219    15264   \n...                                                     ...      ...   \n15     1           0            1                213.190981    13080   \n                   1            0                 86.664974    15264   \n                                1                 69.265675    15264   \n                   3            0                205.638481    15264   \n                                1                212.751190    15264   \n\n                                                                     ...  \\\n                                                               mean  ...   \ncounty is_business product_type is_consumption                       ...   \n0      0           1            0               2022-07-15 23:30:00  ...   \n                                1               2022-07-15 23:30:00  ...   \n                   2            0               2022-07-15 23:30:00  ...   \n                                1               2022-07-15 23:30:00  ...   \n                   3            0               2022-07-15 23:30:00  ...   \n...                                                             ...  ...   \n15     1           0            1               2022-08-30 11:30:00  ...   \n                   1            0               2022-07-15 23:30:00  ...   \n                                1               2022-07-15 23:30:00  ...   \n                   3            0               2022-07-15 23:30:00  ...   \n                                1               2022-07-15 23:30:00  ...   \n\n                                               direct_solar_radiation  \\\n                                                                  max   \ncounty is_business product_type is_consumption                          \n0      0           1            0                               685.0   \n                                1                               685.0   \n                   2            0                               685.0   \n                                1                               685.0   \n                   3            0                               685.0   \n...                                                               ...   \n15     1           0            1                               710.6   \n                   1            0                               710.6   \n                                1                               710.6   \n                   3            0                               710.6   \n                                1                               710.6   \n\n                                                           diffuse_radiation  \\\n                                                       std             count   \ncounty is_business product_type is_consumption                                 \n0      0           1            0               130.358260           15253.0   \n                                1               130.358260           15253.0   \n                   2            0               130.358260           15253.0   \n                                1               130.358260           15253.0   \n                   3            0               130.358260           15253.0   \n...                                                    ...               ...   \n15     1           0            1               131.992968           13080.0   \n                   1            0               125.435838           15253.0   \n                                1               125.435838           15253.0   \n                   3            0               125.435838           15253.0   \n                                1               125.435838           15253.0   \n\n                                                                               \\\n                                                     mean  min  25%       50%   \ncounty is_business product_type is_consumption                                  \n0      0           1            0               41.033097  0.0  0.0  0.666667   \n                                1               41.033097  0.0  0.0  0.666667   \n                   2            0               41.033097  0.0  0.0  0.666667   \n                                1               41.033097  0.0  0.0  0.666667   \n                   3            0               41.033097  0.0  0.0  0.666667   \n...                                                   ...  ...  ...       ...   \n15     1           0            1               45.685336  0.0  0.0  1.400000   \n                   1            0               43.485295  0.0  0.0  0.800000   \n                                1               43.485295  0.0  0.0  0.800000   \n                   3            0               43.485295  0.0  0.0  0.800000   \n                                1               43.485295  0.0  0.0  0.800000   \n\n                                                                        \n                                                 75%    max        std  \ncounty is_business product_type is_consumption                          \n0      0           1            0               73.0  339.5  60.169203  \n                                1               73.0  339.5  60.169203  \n                   2            0               73.0  339.5  60.169203  \n                                1               73.0  339.5  60.169203  \n                   3            0               73.0  339.5  60.169203  \n...                                              ...    ...        ...  \n15     1           0            1               80.8  364.0  65.918644  \n                   1            0               75.6  364.0  63.893546  \n                                1               75.6  364.0  63.893546  \n                   3            0               75.6  364.0  63.893546  \n                                1               75.6  364.0  63.893546  \n\n[138 rows x 400 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th colspan=\"8\" halign=\"left\">target</th>\n      <th colspan=\"2\" halign=\"left\">datetime</th>\n      <th>...</th>\n      <th colspan=\"2\" halign=\"left\">direct_solar_radiation</th>\n      <th colspan=\"8\" halign=\"left\">diffuse_radiation</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>count</th>\n      <th>mean</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>...</th>\n      <th>max</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>min</th>\n      <th>25%</th>\n      <th>50%</th>\n      <th>75%</th>\n      <th>max</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>county</th>\n      <th>is_business</th>\n      <th>product_type</th>\n      <th>is_consumption</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th rowspan=\"2\" valign=\"top\">1</th>\n      <th>0</th>\n      <td>15260.0</td>\n      <td>220.606349</td>\n      <td>0.000</td>\n      <td>0.18300</td>\n      <td>1.5010</td>\n      <td>112.36225</td>\n      <td>3445.013</td>\n      <td>509.590282</td>\n      <td>15264</td>\n      <td>2022-07-15 23:30:00</td>\n      <td>...</td>\n      <td>685.0</td>\n      <td>130.358260</td>\n      <td>15253.0</td>\n      <td>41.033097</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>73.0</td>\n      <td>339.5</td>\n      <td>60.169203</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15260.0</td>\n      <td>442.797622</td>\n      <td>22.972</td>\n      <td>185.90725</td>\n      <td>379.2575</td>\n      <td>602.03550</td>\n      <td>1638.667</td>\n      <td>316.116769</td>\n      <td>15264</td>\n      <td>2022-07-15 23:30:00</td>\n      <td>...</td>\n      <td>685.0</td>\n      <td>130.358260</td>\n      <td>15253.0</td>\n      <td>41.033097</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>73.0</td>\n      <td>339.5</td>\n      <td>60.169203</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">2</th>\n      <th>0</th>\n      <td>15260.0</td>\n      <td>8.372791</td>\n      <td>0.000</td>\n      <td>0.00000</td>\n      <td>0.0010</td>\n      <td>5.07525</td>\n      <td>113.911</td>\n      <td>18.232197</td>\n      <td>15264</td>\n      <td>2022-07-15 23:30:00</td>\n      <td>...</td>\n      <td>685.0</td>\n      <td>130.358260</td>\n      <td>15253.0</td>\n      <td>41.033097</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>73.0</td>\n      <td>339.5</td>\n      <td>60.169203</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15260.0</td>\n      <td>23.173754</td>\n      <td>0.644</td>\n      <td>10.93075</td>\n      <td>21.3120</td>\n      <td>33.35375</td>\n      <td>76.821</td>\n      <td>14.296245</td>\n      <td>15264</td>\n      <td>2022-07-15 23:30:00</td>\n      <td>...</td>\n      <td>685.0</td>\n      <td>130.358260</td>\n      <td>15253.0</td>\n      <td>41.033097</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>73.0</td>\n      <td>339.5</td>\n      <td>60.169203</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <th>0</th>\n      <td>15260.0</td>\n      <td>759.214344</td>\n      <td>0.000</td>\n      <td>1.64175</td>\n      <td>8.6195</td>\n      <td>466.78150</td>\n      <td>11209.014</td>\n      <td>1664.822219</td>\n      <td>15264</td>\n      <td>2022-07-15 23:30:00</td>\n      <td>...</td>\n      <td>685.0</td>\n      <td>130.358260</td>\n      <td>15253.0</td>\n      <td>41.033097</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.666667</td>\n      <td>73.0</td>\n      <td>339.5</td>\n      <td>60.169203</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">15</th>\n      <th rowspan=\"5\" valign=\"top\">1</th>\n      <th>0</th>\n      <th>1</th>\n      <td>13077.0</td>\n      <td>331.619296</td>\n      <td>23.526</td>\n      <td>178.26700</td>\n      <td>244.6720</td>\n      <td>474.40200</td>\n      <td>1030.669</td>\n      <td>213.190981</td>\n      <td>13080</td>\n      <td>2022-08-30 11:30:00</td>\n      <td>...</td>\n      <td>710.6</td>\n      <td>131.992968</td>\n      <td>13080.0</td>\n      <td>45.685336</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.400000</td>\n      <td>80.8</td>\n      <td>364.0</td>\n      <td>65.918644</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">1</th>\n      <th>0</th>\n      <td>15260.0</td>\n      <td>41.582167</td>\n      <td>0.000</td>\n      <td>0.00000</td>\n      <td>0.0230</td>\n      <td>26.43675</td>\n      <td>474.244</td>\n      <td>86.664974</td>\n      <td>15264</td>\n      <td>2022-07-15 23:30:00</td>\n      <td>...</td>\n      <td>710.6</td>\n      <td>125.435838</td>\n      <td>15253.0</td>\n      <td>43.485295</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.800000</td>\n      <td>75.6</td>\n      <td>364.0</td>\n      <td>63.893546</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15260.0</td>\n      <td>79.601392</td>\n      <td>0.485</td>\n      <td>32.20950</td>\n      <td>55.8570</td>\n      <td>99.91600</td>\n      <td>426.108</td>\n      <td>69.265675</td>\n      <td>15264</td>\n      <td>2022-07-15 23:30:00</td>\n      <td>...</td>\n      <td>710.6</td>\n      <td>125.435838</td>\n      <td>15253.0</td>\n      <td>43.485295</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.800000</td>\n      <td>75.6</td>\n      <td>364.0</td>\n      <td>63.893546</td>\n    </tr>\n    <tr>\n      <th rowspan=\"2\" valign=\"top\">3</th>\n      <th>0</th>\n      <td>15260.0</td>\n      <td>94.133136</td>\n      <td>0.000</td>\n      <td>0.00000</td>\n      <td>0.7130</td>\n      <td>53.52350</td>\n      <td>1421.238</td>\n      <td>205.638481</td>\n      <td>15264</td>\n      <td>2022-07-15 23:30:00</td>\n      <td>...</td>\n      <td>710.6</td>\n      <td>125.435838</td>\n      <td>15253.0</td>\n      <td>43.485295</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.800000</td>\n      <td>75.6</td>\n      <td>364.0</td>\n      <td>63.893546</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>15260.0</td>\n      <td>408.428530</td>\n      <td>13.591</td>\n      <td>281.34600</td>\n      <td>350.3970</td>\n      <td>487.99400</td>\n      <td>1349.640</td>\n      <td>212.751190</td>\n      <td>15264</td>\n      <td>2022-07-15 23:30:00</td>\n      <td>...</td>\n      <td>710.6</td>\n      <td>125.435838</td>\n      <td>15253.0</td>\n      <td>43.485295</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.800000</td>\n      <td>75.6</td>\n      <td>364.0</td>\n      <td>63.893546</td>\n    </tr>\n  </tbody>\n</table>\n<p>138 rows × 400 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import QuantileTransformer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:39:18.076338Z","iopub.execute_input":"2024-07-18T15:39:18.076683Z","iopub.status.idle":"2024-07-18T15:39:18.090704Z","shell.execute_reply.started":"2024-07-18T15:39:18.076655Z","shell.execute_reply":"2024-07-18T15:39:18.089475Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the main determining columns and the target variable\nmain_columns = ['is_business', 'county', 'product_type', 'eic_count','cloudcover_total','direct_solar_radiation'] \ntarget_column = 'target'\n\n# Remove rows with missing values in the target variable\ncombined_df = combined_df.dropna(subset=[target_column])\n\n# Remove rows with missing values in the main determining columns\ncombined_df = combined_df.dropna(subset=main_columns)\n\n# Split the dataset into features and target variable\nX = combined_df[main_columns]\ny = combined_df[target_column]\n\n# Debugging step to check for any remaining NaNs\nprint(f'Number of NaNs in target variable y: {y.isna().sum()}')\nprint(f'Number of NaNs in feature variables X:\\n{X.isna().sum()}')\n\n# Ensure no NaNs remain in the data\nif y.isna().sum() > 0 or X.isna().sum().sum() > 0:\n    raise ValueError(\"There are still NaNs in the data after attempting to drop them.\")\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Debugging step to check the shapes of training and testing sets\nprint(f'Shape of X_train: {X_train.shape}')\nprint(f'Shape of X_test: {X_test.shape}')\nprint(f'Shape of y_train: {y_train.shape}')\nprint(f'Shape of y_test: {y_test.shape}')\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Build the linear regression model\nmodel = LinearRegression()\n\n# Train the model\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test_scaled)\n\n# Evaluate the model\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(f'Mean Squared Error: {mse}')\nprint(f'R^2 Score: {r2}')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:39:18.092563Z","iopub.execute_input":"2024-07-18T15:39:18.093309Z","iopub.status.idle":"2024-07-18T15:39:20.323995Z","shell.execute_reply.started":"2024-07-18T15:39:18.093267Z","shell.execute_reply":"2024-07-18T15:39:20.322727Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Number of NaNs in target variable y: 0\nNumber of NaNs in feature variables X:\nis_business               0\ncounty                    0\nproduct_type              0\neic_count                 0\ncloudcover_total          0\ndirect_solar_radiation    0\ndtype: int64\nShape of X_train: (1583795, 6)\nShape of X_test: (395949, 6)\nShape of y_train: (1583795,)\nShape of y_test: (395949,)\nMean Squared Error: 702038.7355248864\nR^2 Score: 0.16274737608969336\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the main determining columns and the target variable\nmain_columns = ['is_business', 'county', 'product_type', 'eic_count','cloudcover_total','direct_solar_radiation'] \ntarget_column = 'target'\n\n# Remove rows with missing values in the target variable\ncombined_df = combined_df.dropna(subset=[target_column])\n\n# Remove rows with missing values in the main determining columns\ncombined_df = combined_df.dropna(subset=main_columns)\n\n# Split the dataset into features and target variable\nX = combined_df[main_columns]\ny = combined_df[target_column]\n\n# Debugging step to check for any remaining NaNs\nprint(f'Number of NaNs in target variable y: {y.isna().sum()}')\nprint(f'Number of NaNs in feature variables X:\\n{X.isna().sum()}')\n\n# Ensure no NaNs remain in the data\nif y.isna().sum() > 0 or X.isna().sum().sum() > 0:\n    raise ValueError(\"There are still NaNs in the data after attempting to drop them.\")\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Debugging step to check the shapes of training and testing sets\nprint(f'Shape of X_train: {X_train.shape}')\nprint(f'Shape of X_test: {X_test.shape}')\nprint(f'Shape of y_train: {y_train.shape}')\nprint(f'Shape of y_test: {y_test.shape}')\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Random Forest\nrf_model = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_model.fit(X_train_scaled, y_train)\ny_pred_rf = rf_model.predict(X_test_scaled)\nmse_rf = mean_squared_error(y_test, y_pred_rf)\nr2_rf = r2_score(y_test, y_pred_rf)\n\n\nprint(f'Mean Squared Error RF: {mse_rf}')\nprint(f'R^2 Score RF: {r2_rf}')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:39:20.326254Z","iopub.execute_input":"2024-07-18T15:39:20.327854Z","iopub.status.idle":"2024-07-18T15:49:05.216040Z","shell.execute_reply.started":"2024-07-18T15:39:20.327807Z","shell.execute_reply":"2024-07-18T15:49:05.214213Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Number of NaNs in target variable y: 0\nNumber of NaNs in feature variables X:\nis_business               0\ncounty                    0\nproduct_type              0\neic_count                 0\ncloudcover_total          0\ndirect_solar_radiation    0\ndtype: int64\nShape of X_train: (1583795, 6)\nShape of X_test: (395949, 6)\nShape of y_train: (1583795,)\nShape of y_test: (395949,)\nMean Squared Error RF: 802762.5352803902\nR^2 Score RF: 0.042623996327092795\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Auto regression**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom statsmodels.tsa.ar_model import AutoReg\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the main determining columns and the target variable\nmain_columns = ['is_business', 'county', 'product_type', 'eic_count','cloudcover_total','direct_solar_radiation'] \ntarget_column = 'target'\n\n# Remove rows with missing values in the target variable\ncombined_df = combined_df.dropna(subset=[target_column])\n\n# Remove rows with missing values in the main determining columns\ncombined_df = combined_df.dropna(subset=main_columns)\n\n# Split the dataset into features and target variable\nX = combined_df[main_columns]\ny = combined_df[target_column]\n\n# Debugging step to check for any remaining NaNs\nprint(f'Number of NaNs in target variable y: {y.isna().sum()}')\nprint(f'Number of NaNs in feature variables X:\\n{X.isna().sum()}')\n\n# Ensure no NaNs remain in the data\nif y.isna().sum() > 0 or X.isna().sum().sum() > 0:\n    raise ValueError(\"There are still NaNs in the data after attempting to drop them.\")\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Debugging step to check the shapes of training and testing sets\nprint(f'Shape of X_train: {X_train.shape}')\nprint(f'Shape of X_test: {X_test.shape}')\nprint(f'Shape of y_train: {y_train.shape}')\nprint(f'Shape of y_test: {y_test.shape}')\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\ny_train_ar = y_train.reset_index(drop=True)\nar_model = AutoReg(y_train_ar, lags=1).fit()\ny_pred_ar = ar_model.predict(start=len(y_train_ar), end=len(y_train_ar) + len(y_test) - 1)\nmse_ar = mean_squared_error(y_test, y_pred_ar)\nr2_ar = r2_score(y_test, y_pred_ar)\n\nprint(f'Mean Squared Error: {mse_ar}')\nprint(f'R^2 Score: {r2_ar}')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:49:05.218127Z","iopub.execute_input":"2024-07-18T15:49:05.218562Z","iopub.status.idle":"2024-07-18T15:49:09.388174Z","shell.execute_reply.started":"2024-07-18T15:49:05.218518Z","shell.execute_reply":"2024-07-18T15:49:09.387064Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Number of NaNs in target variable y: 0\nNumber of NaNs in feature variables X:\nis_business               0\ncounty                    0\nproduct_type              0\neic_count                 0\ncloudcover_total          0\ndirect_solar_radiation    0\ndtype: int64\nShape of X_train: (1583795, 6)\nShape of X_test: (395949, 6)\nShape of y_train: (1583795,)\nShape of y_test: (395949,)\nMean Squared Error: 838502.9285783482\nR^2 Score: -5.9232931004515876e-08\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**SARIMA**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Define the main determining columns and the target variable\nmain_columns = ['is_business', 'county', 'product_type','cloudcover_total','direct_solar_radiation'] \ntarget_column = 'target'\n\n# Remove rows with missing values in the target variable\ncombined_df = combined_df.dropna(subset=[target_column])\n\n# Remove rows with missing values in the main determining columns\ncombined_df = combined_df.dropna(subset=main_columns)\n\n# Split the dataset into features and target variable\nX = combined_df[main_columns]\ny = combined_df[target_column]\n\n# Debugging step to check for any remaining NaNs\nprint(f'Number of NaNs in target variable y: {y.isna().sum()}')\nprint(f'Number of NaNs in feature variables X:\\n{X.isna().sum()}')\n\n# Ensure no NaNs remain in the data\nif y.isna().sum() > 0 or X.isna().sum().sum() > 0:\n    raise ValueError(\"There are still NaNs in the data after attempting to drop them.\")\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Debugging step to check the shapes of training and testing sets\nprint(f'Shape of X_train: {X_train.shape}')\nprint(f'Shape of X_test: {X_test.shape}')\nprint(f'Shape of y_train: {y_train.shape}')\nprint(f'Shape of y_test: {y_test.shape}')\n\n# Standardize the features\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Random Forest\nrf_model_dif = RandomForestRegressor(n_estimators=100, random_state=42)\nrf_model_dif.fit(X_train_scaled, y_train)\ny_pred_rf_dif = rf_model_dif.predict(X_test_scaled)\nmse_rf_dif = mean_squared_error(y_test, y_pred_rf_dif)\nr2_rf_dif = r2_score(y_test, y_pred_rf_dif)\n\nprint(f'Mean Squared Error RF: {mse_rf_dif}')\nprint(f'R^2 Score RF: {r2_rf_dif}')","metadata":{"execution":{"iopub.status.busy":"2024-07-18T15:49:09.390016Z","iopub.execute_input":"2024-07-18T15:49:09.390351Z","iopub.status.idle":"2024-07-18T15:56:00.755025Z","shell.execute_reply.started":"2024-07-18T15:49:09.390322Z","shell.execute_reply":"2024-07-18T15:56:00.753766Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Number of NaNs in target variable y: 0\nNumber of NaNs in feature variables X:\nis_business               0\ncounty                    0\nproduct_type              0\ncloudcover_total          0\ndirect_solar_radiation    0\ndtype: int64\nShape of X_train: (1583795, 5)\nShape of X_test: (395949, 5)\nShape of y_train: (1583795,)\nShape of y_test: (395949,)\nMean Squared Error RF: 664868.4905432126\nR^2 Score RF: 0.2070766752686446\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}